// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// RUN: %clang_cc1 -triple arm64-none-linux-gnu -target-feature +neon \
// RUN:  -disable-O0-optnone -ffp-contract=fast -emit-llvm -o - %s | opt -S -passes=mem2reg | FileCheck %s

// REQUIRES: aarch64-registered-target || arm-registered-target

#include <arm_neon.h>

// CHECK-LABEL: define dso_local <8 x b8> @test_shift_vshr(
// CHECK-SAME: <8 x b8> noundef [[A:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[REF_TMP:%.*]] = alloca <8 x b8>, align 8
// CHECK-NEXT:    [[TMP0:%.*]] = bytecast <8 x b8> [[A]] to <8 x i8>
// CHECK-NEXT:    [[VSHR_N:%.*]] = lshr <8 x i8> [[TMP0]], splat (i8 5)
// CHECK-NEXT:    store <8 x i8> [[VSHR_N]], ptr [[REF_TMP]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x b8>, ptr [[REF_TMP]], align 8
// CHECK-NEXT:    ret <8 x b8> [[TMP1]]
//
uint8x8_t test_shift_vshr(uint8x8_t a) {
  return vshr_n_u8(a, 5);
}

// CHECK-LABEL: define dso_local <8 x b8> @test_shift_vshr_smax(
// CHECK-SAME: <8 x b8> noundef [[A:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[REF_TMP:%.*]] = alloca <8 x b8>, align 8
// CHECK-NEXT:    [[TMP0:%.*]] = bytecast <8 x b8> [[A]] to <8 x i8>
// CHECK-NEXT:    [[VSHR_N:%.*]] = ashr <8 x i8> [[TMP0]], splat (i8 7)
// CHECK-NEXT:    store <8 x i8> [[VSHR_N]], ptr [[REF_TMP]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x b8>, ptr [[REF_TMP]], align 8
// CHECK-NEXT:    ret <8 x b8> [[TMP1]]
//
int8x8_t test_shift_vshr_smax(int8x8_t a) {
  return vshr_n_s8(a, 8);
}

// CHECK-LABEL: define dso_local <8 x b8> @test_shift_vshr_umax(
// CHECK-SAME: <8 x b8> noundef [[A:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[REF_TMP:%.*]] = alloca <8 x b8>, align 8
// CHECK-NEXT:    [[TMP0:%.*]] = bytecast <8 x b8> [[A]] to <8 x i8>
// CHECK-NEXT:    store <8 x i8> zeroinitializer, ptr [[REF_TMP]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x b8>, ptr [[REF_TMP]], align 8
// CHECK-NEXT:    ret <8 x b8> [[TMP1]]
//
uint8x8_t test_shift_vshr_umax(uint8x8_t a) {
  return vshr_n_u8(a, 8);
}

// CHECK-LABEL: define dso_local <8 x b8> @test_shift_vsra(
// CHECK-SAME: <8 x b8> noundef [[A:%.*]], <8 x b8> noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[REF_TMP:%.*]] = alloca <8 x b8>, align 8
// CHECK-NEXT:    [[TMP0:%.*]] = bytecast <8 x b8> [[A]] to <8 x i8>
// CHECK-NEXT:    [[TMP1:%.*]] = bytecast <8 x b8> [[B]] to <8 x i8>
// CHECK-NEXT:    [[VSRA_N:%.*]] = lshr <8 x i8> [[TMP1]], splat (i8 5)
// CHECK-NEXT:    [[TMP2:%.*]] = add <8 x i8> [[TMP0]], [[VSRA_N]]
// CHECK-NEXT:    store <8 x i8> [[TMP2]], ptr [[REF_TMP]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load <8 x b8>, ptr [[REF_TMP]], align 8
// CHECK-NEXT:    ret <8 x b8> [[TMP3]]
//
uint8x8_t test_shift_vsra(uint8x8_t a, uint8x8_t b) {
  return vsra_n_u8(a, b, 5);
}

// CHECK-LABEL: define dso_local <8 x b8> @test_shift_vsra_smax(
// CHECK-SAME: <8 x b8> noundef [[A:%.*]], <8 x b8> noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[REF_TMP:%.*]] = alloca <8 x b8>, align 8
// CHECK-NEXT:    [[TMP0:%.*]] = bytecast <8 x b8> [[A]] to <8 x i8>
// CHECK-NEXT:    [[TMP1:%.*]] = bytecast <8 x b8> [[B]] to <8 x i8>
// CHECK-NEXT:    [[VSRA_N:%.*]] = ashr <8 x i8> [[TMP1]], splat (i8 7)
// CHECK-NEXT:    [[TMP2:%.*]] = add <8 x i8> [[TMP0]], [[VSRA_N]]
// CHECK-NEXT:    store <8 x i8> [[TMP2]], ptr [[REF_TMP]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load <8 x b8>, ptr [[REF_TMP]], align 8
// CHECK-NEXT:    ret <8 x b8> [[TMP3]]
//
int8x8_t test_shift_vsra_smax(int8x8_t a, int8x8_t b) {
  return vsra_n_s8(a, b, 8);
}

// CHECK-LABEL: define dso_local <8 x b8> @test_shift_vsra_umax(
// CHECK-SAME: <8 x b8> noundef [[A:%.*]], <8 x b8> noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[REF_TMP:%.*]] = alloca <8 x b8>, align 8
// CHECK-NEXT:    [[TMP0:%.*]] = bytecast <8 x b8> [[A]] to <8 x i8>
// CHECK-NEXT:    [[TMP1:%.*]] = bytecast <8 x b8> [[B]] to <8 x i8>
// CHECK-NEXT:    [[TMP2:%.*]] = add <8 x i8> [[TMP0]], zeroinitializer
// CHECK-NEXT:    store <8 x i8> [[TMP2]], ptr [[REF_TMP]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load <8 x b8>, ptr [[REF_TMP]], align 8
// CHECK-NEXT:    ret <8 x b8> [[TMP3]]
//
uint8x8_t test_shift_vsra_umax(uint8x8_t a, uint8x8_t b) {
  return vsra_n_u8(a, b, 8);
}
